{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('new train data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = ['C13', 'TransactionDT', 'TransactionAmt', 'card1', 'C14'] #from feature_importances.index[:5] preprocessing_models_roc\n",
    "#for i in top_5:\n",
    "print (type(training[top_5[0]][0]))\n",
    "print (type(training[top_5[1]][0]))\n",
    "print (type(training[top_5[2]][0]))\n",
    "print (type(training[top_5[3]][0]))\n",
    "print (type(training[top_5[4]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['isFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix for top 5 important vars \n",
    "sns.pairplot(training[top_5])\n",
    "sns.plt.show(hue = 'isfraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar column names have high correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix as heat map\n",
    "import seaborn as sns\n",
    "corr = training[top_5].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9',\n",
    "       'C10', 'C11', 'C12', 'C13', 'C14']\n",
    "V = ['V95', 'V96', 'V97',\n",
    "       'V98', 'V99', 'V100', 'V101', 'V102', 'V103', 'V104', 'V105',\n",
    "       'V106', 'V107', 'V108', 'V109', 'V110', 'V111', 'V112', 'V113',\n",
    "       'V114', 'V115', 'V116', 'V117', 'V118', 'V119', 'V120', 'V121',\n",
    "       'V122', 'V123', 'V124', 'V125', 'V126', 'V127', 'V128', 'V129',\n",
    "       'V130', 'V131', 'V132', 'V133', 'V134', 'V135', 'V136', 'V137',\n",
    "       'V279', 'V280', 'V281', 'V282', 'V283', 'V284', 'V285', 'V286',\n",
    "       'V287', 'V288', 'V289', 'V290', 'V291', 'V292', 'V293', 'V294',\n",
    "       'V295', 'V296', 'V297', 'V298', 'V299', 'V300', 'V301', 'V302',\n",
    "       'V303', 'V304', 'V305', 'V306', 'V307', 'V308', 'V309', 'V310',\n",
    "       'V311', 'V312', 'V313', 'V314', 'V315', 'V316', 'V317', 'V318',\n",
    "       'V319', 'V320', 'V321']\n",
    "D = ['D1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix as heat map\n",
    "import seaborn as sns\n",
    "corr = training[top_5].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix as heat map\n",
    "import seaborn as sns\n",
    "corr = training[C].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    "    );\n",
    "\n",
    "# C3, 5, and 9 not highly correlated with other C's. C stands for count of something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix as heat map\n",
    "import seaborn as sns\n",
    "corr = training[V].corr()\n",
    "ax = sns.heatmap(\n",
    "    corr,\n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat high dimensional version of heat map for V values\n",
    "# note doubled columns\n",
    "# ref: https://stackoverflow.com/questions/50997662/how-to-plot-heatmap-for-high-dimensional-dataset\n",
    "df2 = training[V].copy()\n",
    "df2.columns = \"c_\" + df2.columns\n",
    "df3 = pd.concat([training[V], df2], axis=1)\n",
    "\n",
    "# get the correlation coefficient between the different columns\n",
    "corr = df3.iloc[:, 1:].corr()\n",
    "arr_corr = corr.as_matrix()\n",
    "\n",
    "# mask out the top triangle\n",
    "arr_corr[np.triu_indices_from(arr_corr)] = np.nan\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(24, 18))\n",
    "\n",
    "hm = sns.heatmap(arr_corr, cbar=True, vmin=-0.5, vmax=0.5,\n",
    "                 fmt='.2f', annot_kws={'size': 3}, annot=True, \n",
    "                 square=True, cmap=plt.cm.Blues)\n",
    "\n",
    "ticks = np.arange(corr.shape[0]) + 0.5\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(corr.columns, rotation=90, fontsize=8)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_yticklabels(corr.index, rotation=360, fontsize=8)\n",
    "\n",
    "ax.set_title('correlation matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"corr_matrix_incl_anno_double.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['V305'].value_counts() #V305 is uncorrelated with other features because it only has one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = training.isFraud.isnull().astype(int)\n",
    "col[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create binary columns indicating NA value for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-50663f08c0a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#TEST ON THREE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbinary_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'i'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnew_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbinary_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#1 means null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'columns' is not defined"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# for i in range(len(columns)): #TEST ON THREE\n",
    "#     col = training.columns[i].isnull().astype(int)\n",
    "#     binary_name = 'i' + '_b'\n",
    "#     new_df = pd.DataFrame(data = col, columns = [binary_name]) #1 means null\n",
    "#     pd.concat([training, new_df], axis = 1)\n",
    "# training.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced = pd.read_csv('../Data Processing/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(balanced.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(balanced.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN       508189\n",
       "0.0        72668\n",
       "2301.0       925\n",
       "100.0        835\n",
       "50.0         809\n",
       "           ...  \n",
       "1385.0         1\n",
       "532.0          1\n",
       "1395.0         1\n",
       "1416.0         1\n",
       "273.0          1\n",
       "Name: V335, Length: 673, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced['V335'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = balanced.columns.values\n",
    "\n",
    "for i in range(len(cols)):\n",
    "    binary_col_name = cols[i] + '_b'\n",
    "#     print(binary_col_name)\n",
    "    balanced[binary_col_name] = np.where(balanced[cols[i]].notnull(), 0, 1)\n",
    "    \n",
    "len(balanced.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    508189\n",
       "0     82351\n",
       "Name: V335_b, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced['V335_b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "788/394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_name = columns[0]\n",
    "# type(col_name)\n",
    "# # training.col_name.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "# df = pd.DataFrame(data=d)\n",
    "# df\n",
    "# training['adf;lasjd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2 = {'col1': [1, 2], 'col2': [3, 4]}\n",
    "# df2 = pd.DataFrame(data=d)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([df, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing stuff\n",
    "# for i in list_ib:\n",
    "#     for j in list_ib:\n",
    "#         if i == j:\n",
    "#             break\n",
    "#         else:            \n",
    "#             bina = df[i]*df[j]\n",
    "#             print(i,j)\n",
    "            \n",
    "# new_df = pd.DataFrame(data={'i':i, 'j':j, 'bina':bina}, columns=['i','j','bina'])\n",
    "# pd.concat([df, new_df], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
